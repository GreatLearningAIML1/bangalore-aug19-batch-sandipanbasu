{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Project_Sarcasm_Detection_Questions.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pp68FAQf9aMN"
      },
      "source": [
        "# Sarcasm Detection\n",
        " **Acknowledgement**\n",
        "\n",
        "Misra, Rishabh, and Prahal Arora. \"Sarcasm Detection using Hybrid Neural Network.\" arXiv preprint arXiv:1908.07414 (2019).\n",
        "\n",
        "**Required Files given in below link.**\n",
        "\n",
        "https://drive.google.com/drive/folders/1xUnF35naPGU63xwRDVGc-DkZ3M8V5mMk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mac-7MuMyFz",
        "colab_type": "text"
      },
      "source": [
        "# PLEASE NOTE THAT THIS NOTEBOOK IS BUILT IN GOOGLE COLAB AND ASSUMES LOCAL DRIVE OF COLAB ENV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S3Wj_mIZ8S3K"
      },
      "source": [
        "## Install `Tensorflow2.0` "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v9kv9tyJ77eF"
      },
      "source": [
        "## Import "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu7J7qt5UzJV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "fbdf30f3-aa77-4943-9e0e-94fa54b9e075"
      },
      "source": [
        "import warnings\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import preprocessing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pprint\n",
        "from tensorflow.keras.layers import Bidirectional,LSTM,Dense,Dropout,BatchNormalization,Flatten,Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from numpy import array\n",
        "import nltk\n",
        "import re\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize \n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8aLqG3XU42E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "44e7590e-d6e5-496d-dabf-2288125d071d"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0mgRpOvFMjKR",
        "colab": {}
      },
      "source": [
        "#Set your project path \n",
        "project_path = \"/content/drive/My Drive/\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WXYwajPeQbRq"
      },
      "source": [
        "#**## Reading and Exploring Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vAk6BRUh8CqL"
      },
      "source": [
        "## Read Data \"Sarcasm_Headlines_Dataset.json\". Explore the data and get  some insights about the data. ( 4 marks)\n",
        "Hint - As its in json format you need to use pandas.read_json function. Give paraemeter lines = True."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "StSLB-T8PuGr",
        "colab": {}
      },
      "source": [
        "sarcasm_df=pd.read_json(\"https://raw.githubusercontent.com/rishabhmisra/News-Headlines-Dataset-For-Sarcasm-Detection/master/Sarcasm_Headlines_Dataset.json\",lines=True )"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YksEdfTdWNpg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "bb7d09b1-d66c-4c45-86e6-258686b6624f"
      },
      "source": [
        "sarcasm_df.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>is_sarcastic</th>\n",
              "      <th>headline</th>\n",
              "      <th>article_link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
              "      <td>https://www.theonion.com/thirtysomething-scien...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>dem rep. totally nails why congress is falling...</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/donna-edw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/eat-your-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>inclement weather prevents liar from getting t...</td>\n",
              "      <td>https://local.theonion.com/inclement-weather-p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>mother comes pretty close to using word 'strea...</td>\n",
              "      <td>https://www.theonion.com/mother-comes-pretty-c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   is_sarcastic  ...                                       article_link\n",
              "0             1  ...  https://www.theonion.com/thirtysomething-scien...\n",
              "1             0  ...  https://www.huffingtonpost.com/entry/donna-edw...\n",
              "2             0  ...  https://www.huffingtonpost.com/entry/eat-your-...\n",
              "3             1  ...  https://local.theonion.com/inclement-weather-p...\n",
              "4             1  ...  https://www.theonion.com/mother-comes-pretty-c...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z6pXf7A78E2H"
      },
      "source": [
        "## Drop `article_link` from dataset. ( 2 marks)\n",
        "As we only need headline text data and is_sarcastic column for this project. We can drop artical link column here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VLSVsvrlP9qD",
        "colab": {}
      },
      "source": [
        "sarcasm_df.drop(labels='article_link', axis=1,inplace=True)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72n8hgLFWkL_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "906fef3d-b994-4ab7-99f0-a65b1aae8f58"
      },
      "source": [
        "sarcasm_df.head(2)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>is_sarcastic</th>\n",
              "      <th>headline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>dem rep. totally nails why congress is falling...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   is_sarcastic                                           headline\n",
              "0             1  thirtysomething scientists unveil doomsday clo...\n",
              "1             0  dem rep. totally nails why congress is falling..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vPXhyUNYObF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "68e7cb53-5626-474b-c1d2-655694ded962"
      },
      "source": [
        "sarcasm_df.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28619, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-8P-zkAacDA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "42bf7ff1-c98c-42a7-b97c-b40657f5f7ca"
      },
      "source": [
        "sarcasm_df.dtypes"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "is_sarcastic     int64\n",
              "headline        object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyagoOLbYRiI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "beb07510-9c49-4f38-e33d-d8bbfeca1bf1"
      },
      "source": [
        "sarcasm_df['is_sarcastic'].value_counts()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    14985\n",
              "1    13634\n",
              "Name: is_sarcastic, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "D0h6IOxU8OdH"
      },
      "source": [
        "## Get the Length of each line and find the maximum length. ( 4 marks)\n",
        "As different lines are of different length. We need to pad the our sequences using the max length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BRAsChZAQmr3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5edea0bb-c968-4784-af03-ac511eaa5626"
      },
      "source": [
        "max_headline=max(len(txt) for txt in sarcasm_df['headline'])\n",
        "max_headline"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "926"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wmfDjB12yWv",
        "colab_type": "text"
      },
      "source": [
        "## Build Vocab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNN36RtXdW5d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3ddc446a-7c60-4908-b61e-fa17232ab02b"
      },
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "# Build tokenizer\n",
        "tokenizer.fit_on_texts(sarcasm_df['headline']) \n",
        "vocab_size = len(tokenizer.word_index)\n",
        "print(vocab_size)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30884\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VPPd0YuPXi2M"
      },
      "source": [
        "#**## Modelling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "35abKfRx8as3"
      },
      "source": [
        "## Import required modules required for modelling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DVel73hYEV4r",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Flatten, Bidirectional, GlobalMaxPool1D\n",
        "from tensorflow.keras.models import Model, Sequential"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9ziybaD1RdD9"
      },
      "source": [
        "# Set Different Parameters for the model. ( 2 marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jPw9gAN_EV6m",
        "colab": {}
      },
      "source": [
        "max_features = 15000\n",
        "embedding_size = 200\n",
        "padding = 'pre'\n",
        "rnn_units=256\n",
        "mask_zero=False\n",
        "return_sequence=False"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9abSe-bM8fn9"
      },
      "source": [
        "## Apply Keras Tokenizer of headline column of your data.  ( 4 marks)\n",
        "Hint - First create a tokenizer instance using Tokenizer(num_words=max_features) \n",
        "And then fit this tokenizer instance on your data column df['headline'] using .fit_on_texts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0Ffi63KsST3P"
      },
      "source": [
        "# Define X and y for your model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmBfOqKQ3wqr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "224a68fc-97ee-4593-9e1a-d72e93b76f17"
      },
      "source": [
        "sarcasm_df_seq = tokenizer.texts_to_sequences(sarcasm_df['headline'])\n",
        "X = tf.keras.preprocessing.sequence.pad_sequences(sarcasm_df_seq, \n",
        "                                                                   maxlen=max_headline,\n",
        "                                                                   padding='pre')\n",
        "y = np.asarray(sarcasm_df['is_sarcastic'])\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28619, 926)\n",
            "(28619,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUo0SdmAoj1n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "59941b31-47b9-4e84-c329-7108e2cef905"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train,test = train_test_split(sarcasm_df,test_size = 0.2)\n",
        "train,val = train_test_split(train,test_size=0.25)\n",
        "\n",
        "print(train.shape)\n",
        "print(test.shape)\n",
        "print(val.shape)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(17171, 2)\n",
            "(5724, 2)\n",
            "(5724, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfK40nEB6W4x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "13d717be-170f-4e54-d372-2ca9b1211530"
      },
      "source": [
        "# X\n",
        "train_sequence = tokenizer.texts_to_sequences(train[\"headline\"].values)\n",
        "test_sequence = tokenizer.texts_to_sequences(test[\"headline\"].values)\n",
        "val_sequence = tokenizer.texts_to_sequences(val[\"headline\"].values)\n",
        "\n",
        "train_sequence = tf.keras.preprocessing.sequence.pad_sequences(train_sequence,\n",
        "                                                               maxlen=max_headline,\n",
        "                                                               padding='pre')\n",
        "test_sequence = tf.keras.preprocessing.sequence.pad_sequences(test_sequence,\n",
        "                                                               maxlen=max_headline,\n",
        "                                                               padding='pre')\n",
        "val_sequence = tf.keras.preprocessing.sequence.pad_sequences(val_sequence,\n",
        "                                                               maxlen=max_headline,\n",
        "                                                               padding='pre')\n",
        "\n",
        "#y\n",
        "y_train = np.asarray(train['is_sarcastic'])\n",
        "y_test = np.asarray(test['is_sarcastic'])\n",
        "y_val = np.asarray(val['is_sarcastic'])\n",
        "\n",
        "len(train_sequence)\n",
        "len(y_train)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17171"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4BTBLgnmrlb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "079b5a54-2898-46e9-a736-7ced5b0313ac"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17171,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WJLyKg-98rH_"
      },
      "source": [
        "## Get the Vocabulary size ( 2 marks)\n",
        "Hint : You can use tokenizer.word_index."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q-2w0gHEUUIo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a05e31d9-f4ce-4d24-9c08-81632d73e24e"
      },
      "source": [
        "vocab_size = len(tokenizer.word_index)\n",
        "print(vocab_size)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30884\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5hjeMi40XcB1"
      },
      "source": [
        "#**## Word Embedding**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bUF1TuQa8ux0"
      },
      "source": [
        "## Get Glove Word Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wr78KLaY7Vij",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "18b69952-396e-4db1-d0d9-528acebe95e0"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-18 05:36:19--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-06-18 05:36:19--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-06-18 05:36:20--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  1.92MB/s    in 6m 29s  \n",
            "\n",
            "2020-06-18 05:42:49 (2.11 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vq5AIfRtMeZh",
        "colab": {}
      },
      "source": [
        "glove_file = \"glove.6B.zip\""
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DJLX_n2WMecA",
        "colab": {}
      },
      "source": [
        "#Extract Glove embedding zip file\n",
        "from zipfile import ZipFile\n",
        "with ZipFile(glove_file, 'r') as z:\n",
        "  z.extractall()"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9IuXlu8-U3HG"
      },
      "source": [
        "# Get the Word Embeddings using Embedding file as given below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "elZ-T5aFGZmZ",
        "colab": {}
      },
      "source": [
        "EMBEDDING_FILE = './glove.6B.200d.txt'\n",
        "\n",
        "embeddings = {}\n",
        "for o in open(EMBEDDING_FILE):\n",
        "    word = o.split(\" \")[0]\n",
        "    # print(word)\n",
        "    embd = o.split(\" \")[1:]\n",
        "    embd = np.asarray(embd, dtype='float32')\n",
        "    # print(embd)\n",
        "    embeddings[word] = embd\n",
        "\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bTPxveDmVCrA"
      },
      "source": [
        "# Create a weight matrix for words in training docs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xQgOhiywU9nU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b4208baf-bdb3-4e97-8b37-c707d41b4fc2"
      },
      "source": [
        "embedding_matrix = np.zeros((vocab_size+1, 200))\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "len(embeddings.values())"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "u7IbWuEX82Ra"
      },
      "source": [
        "## Create and Compile your Model  ( 7 marks)\n",
        "Hint - Use Sequential model instance and then add Embedding layer, Bidirectional(LSTM) layer, then dense and dropout layers as required. \n",
        "In the end add a final dense layer with sigmoid activation for binary classification.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1-TNWISF6ku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# As per https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM, it will use CuDNN Lstm\n",
        "# if below params match\n",
        "# activation == tanh\n",
        "# recurrent_activation == sigmoid\n",
        "# recurrent_dropout == 0\n",
        "# unroll is False\n",
        "# use_bias is True\n",
        "# Inputs are not masked or strictly right padded.\n",
        "\n",
        "def createCUDNNLstm(units,return_state,return_sequences,dropout,name=''):\n",
        "  return layers.LSTM(units=units,\n",
        "                     return_state=return_state,\n",
        "                     return_sequences=return_sequences, \n",
        "                     name = name,\n",
        "                     activation='tanh',\n",
        "                     recurrent_activation='sigmoid',\n",
        "                     recurrent_dropout=0,\n",
        "                     dropout=dropout,\n",
        "                     unroll=False,\n",
        "                     use_bias=True)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2C10njdGWEj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "16e03dcf-02a8-4cf4-a0b2-04e2b5d965c6"
      },
      "source": [
        "strategy = tf.distribute.MirroredStrategy()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d7jhsSgYXG4l",
        "colab": {}
      },
      "source": [
        "### Embedding layer for hint \n",
        "## model.add(Embedding(num_words, embedding_size, weights = [embedding_matrix]))\n",
        "### Bidirectional LSTM layer for hint \n",
        "## model.add(Bidirectional(LSTM(128, return_sequences = True)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MUIk7vdg5yT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with strategy.scope():\n",
        "  model = tf.keras.Sequential()\n",
        "  ## Please note that mask_zero is true to trigger cudn LSTN variant for GPU\n",
        "  model.add(tf.keras.layers.Embedding(input_dim=vocab_size+1,\n",
        "                    output_dim=embedding_size,\n",
        "                    weights=[embedding_matrix],\n",
        "                    trainable=False, mask_zero= False))\n",
        "  model.add(tf.keras.layers.Bidirectional(createCUDNNLstm(units=128,\n",
        "                                                          return_sequences=False, \n",
        "                                                          dropout=0.2, \n",
        "                                                          return_state=False),\n",
        "                                          merge_mode='concat'))\n",
        "  model.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
        "\n",
        "  model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhkQADcbqoCq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "a1431e10-7789-4ab7-eadc-ff7d1ebde1da"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, None, 200)         6177000   \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 256)               336896    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 6,514,153\n",
            "Trainable params: 337,153\n",
            "Non-trainable params: 6,177,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IJFMxZwMWoTw"
      },
      "source": [
        "# Fit your model with a batch size of 100 and validation_split = 0.2. and state the validation accuracy ( 5 marks)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZpVkajCcWnRK",
        "colab": {}
      },
      "source": [
        "batch_size = 100\n",
        "epochs = 5\n",
        "\n",
        "## Add your code here ##"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0ErE3BLmKaH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "3067b658-0413-499c-d33c-9d5dd716c108"
      },
      "source": [
        "with strategy.scope():\n",
        "  model.fit(train_sequence,y_train,\n",
        "            epochs=5,\n",
        "            batch_size=100, validation_data=(val_sequence, y_val))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "172/172 [==============================] - 73s 423ms/step - loss: 0.5436 - accuracy: 0.7242 - val_loss: 0.4528 - val_accuracy: 0.7949\n",
            "Epoch 2/5\n",
            "172/172 [==============================] - 72s 419ms/step - loss: 0.4254 - accuracy: 0.8072 - val_loss: 0.4004 - val_accuracy: 0.8171\n",
            "Epoch 3/5\n",
            "172/172 [==============================] - 72s 418ms/step - loss: 0.3551 - accuracy: 0.8447 - val_loss: 0.3455 - val_accuracy: 0.8510\n",
            "Epoch 4/5\n",
            "172/172 [==============================] - 72s 417ms/step - loss: 0.3143 - accuracy: 0.8642 - val_loss: 0.3291 - val_accuracy: 0.8581\n",
            "Epoch 5/5\n",
            "172/172 [==============================] - 72s 418ms/step - loss: 0.2980 - accuracy: 0.8746 - val_loss: 0.3185 - val_accuracy: 0.8636\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s30jaAS1Oxob",
        "colab_type": "text"
      },
      "source": [
        "Validation Accuracy with Embedding size of 200 and RNN Units of 128 is 86.36"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffEM9RlzOnBM",
        "colab_type": "text"
      },
      "source": [
        "# Model 2- Glove Embedding of 300, With 256 Memory Size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tF3vRSCOlIH",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6_MJYLOqflo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMBEDDING_FILE = './glove.6B.300d.txt'\n",
        "\n",
        "embeddings = {}\n",
        "for o in open(EMBEDDING_FILE):\n",
        "    word = o.split(\" \")[0]\n",
        "    # print(word)\n",
        "    embd = o.split(\" \")[1:]\n",
        "    embd = np.asarray(embd, dtype='float32')\n",
        "    # print(embd)\n",
        "    embeddings[word] = embd"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DBndY2XNrXW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cb580647-50d4-4c48-b8ae-10ef723765d0"
      },
      "source": [
        "embedding_matrix = np.zeros((vocab_size+1, 300))\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "len(embeddings.values())"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyZwZJgVNw7Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e4043a7-790e-4dd2-eba9-57bd46ba8f4c"
      },
      "source": [
        "strategy2 = tf.distribute.MirroredStrategy()\n",
        "with strategy2.scope():\n",
        "  model2 = tf.keras.Sequential()\n",
        "  ## Please note that mask_zero is true to trigger cudn LSTN variant for GPU\n",
        "  model2.add(tf.keras.layers.Embedding(input_dim=vocab_size+1,\n",
        "                    output_dim=300,\n",
        "                    weights=[embedding_matrix],\n",
        "                    trainable=False, mask_zero= False))\n",
        "  model2.add(tf.keras.layers.Dropout(0.2))\n",
        "  model2.add(tf.keras.layers.Bidirectional(createCUDNNLstm(units=256,return_sequences=False, \n",
        "                                                          dropout=0.2, \n",
        "                                                          return_state=False),\n",
        "                                           merge_mode='concat'))\n",
        "  model2.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
        "  model2.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRm5h0Az2ieX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "235f6876-3eb8-4412-d63b-cdd328812aca"
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, None, 300)         9265500   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, None, 300)         0         \n",
            "_________________________________________________________________\n",
            "bidirectional_5 (Bidirection (None, 512)               1140736   \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 10,406,749\n",
            "Trainable params: 1,141,249\n",
            "Non-trainable params: 9,265,500\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPE8IAH1OPTE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "3a203616-aa34-4744-fcd6-5c419e4902f5"
      },
      "source": [
        "with strategy2.scope():\n",
        "  model2.fit(train_sequence,y_train,\n",
        "            epochs=5,\n",
        "            batch_size=100, validation_data=(val_sequence, y_val))  "
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "172/172 [==============================] - 143s 831ms/step - loss: 0.5309 - accuracy: 0.7265 - val_loss: 0.4290 - val_accuracy: 0.8059\n",
            "Epoch 2/5\n",
            "172/172 [==============================] - 141s 821ms/step - loss: 0.6532 - accuracy: 0.6435 - val_loss: 0.5908 - val_accuracy: 0.6979\n",
            "Epoch 3/5\n",
            "172/172 [==============================] - 141s 821ms/step - loss: 0.5290 - accuracy: 0.7379 - val_loss: 0.4520 - val_accuracy: 0.7916\n",
            "Epoch 4/5\n",
            "172/172 [==============================] - 141s 819ms/step - loss: 0.4219 - accuracy: 0.8027 - val_loss: 0.3835 - val_accuracy: 0.8290\n",
            "Epoch 5/5\n",
            "172/172 [==============================] - 141s 819ms/step - loss: 0.3740 - accuracy: 0.8306 - val_loss: 0.3554 - val_accuracy: 0.8431\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbkXFpjcg_d_",
        "colab_type": "text"
      },
      "source": [
        "Validation Accuracy with Embedding size of 300 and RNN Units of 256 is 84.31"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dN_2jmSb5QpO",
        "colab_type": "text"
      },
      "source": [
        "# Model 3- Glove Embedding of 300, With 128 Memory Size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ofFzHPq5YTk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2f596af7-70d1-4cf9-9e3c-0626a7e06e6b"
      },
      "source": [
        "strategy3 = tf.distribute.MirroredStrategy()\n",
        "with strategy3.scope():\n",
        "  model3 = tf.keras.Sequential()\n",
        "  model3.add(tf.keras.layers.Embedding(input_dim=vocab_size+1,\n",
        "                    output_dim=300,\n",
        "                    weights=[embedding_matrix],\n",
        "                    trainable=False, mask_zero= False))\n",
        "  model3.add(tf.keras.layers.Bidirectional(createCUDNNLstm(units=256,return_sequences=False, \n",
        "                                                          dropout=0.2, \n",
        "                                                          return_state=False),\n",
        "                                           merge_mode='concat'))\n",
        "  model3.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
        "  model3.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHIaVeGR5ury",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "d4cf419f-f430-4071-b699-9e0f51f6f71b"
      },
      "source": [
        "model3.summary()"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, None, 300)         9265500   \n",
            "_________________________________________________________________\n",
            "bidirectional_7 (Bidirection (None, 512)               1140736   \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 10,406,749\n",
            "Trainable params: 1,141,249\n",
            "Non-trainable params: 9,265,500\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHGmbgNV6C7h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "098384a3-1160-43bf-96d8-53f22cf0611c"
      },
      "source": [
        "with strategy3.scope():\n",
        "  model3.fit(train_sequence,y_train,\n",
        "            epochs=10,\n",
        "            batch_size=100, validation_data=(val_sequence, y_val))  "
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "172/172 [==============================] - 142s 825ms/step - loss: 0.5253 - accuracy: 0.7357 - val_loss: 0.4299 - val_accuracy: 0.8026\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 139s 809ms/step - loss: 0.4022 - accuracy: 0.8171 - val_loss: 0.3677 - val_accuracy: 0.8361\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 139s 808ms/step - loss: 0.3283 - accuracy: 0.8548 - val_loss: 0.3445 - val_accuracy: 0.8482\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 139s 809ms/step - loss: 0.2786 - accuracy: 0.8811 - val_loss: 0.3245 - val_accuracy: 0.8576\n",
            "Epoch 5/10\n",
            "172/172 [==============================] - 139s 809ms/step - loss: 0.2396 - accuracy: 0.8997 - val_loss: 0.3319 - val_accuracy: 0.8567\n",
            "Epoch 6/10\n",
            "172/172 [==============================] - 139s 810ms/step - loss: 0.2029 - accuracy: 0.9167 - val_loss: 0.3263 - val_accuracy: 0.8613\n",
            "Epoch 7/10\n",
            "172/172 [==============================] - 140s 812ms/step - loss: 0.1652 - accuracy: 0.9341 - val_loss: 0.3456 - val_accuracy: 0.8637\n",
            "Epoch 8/10\n",
            "172/172 [==============================] - 140s 812ms/step - loss: 0.1306 - accuracy: 0.9500 - val_loss: 0.3652 - val_accuracy: 0.8571\n",
            "Epoch 9/10\n",
            "172/172 [==============================] - 140s 812ms/step - loss: 0.1002 - accuracy: 0.9626 - val_loss: 0.3887 - val_accuracy: 0.8620\n",
            "Epoch 10/10\n",
            "172/172 [==============================] - 140s 811ms/step - loss: 0.0840 - accuracy: 0.9697 - val_loss: 0.4193 - val_accuracy: 0.8636\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VRsPwcX-ZcI",
        "colab_type": "text"
      },
      "source": [
        "Validation Accuracy with Embedding size of 300 and RNN Units of 256 with epoch 10 is 86.36"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vghYjdXsUyRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}