{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Project_Sarcasm_Detection_Questions.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pp68FAQf9aMN"
      },
      "source": [
        "# Sarcasm Detection\n",
        " **Acknowledgement**\n",
        "\n",
        "Misra, Rishabh, and Prahal Arora. \"Sarcasm Detection using Hybrid Neural Network.\" arXiv preprint arXiv:1908.07414 (2019).\n",
        "\n",
        "**Required Files given in below link.**\n",
        "\n",
        "https://drive.google.com/drive/folders/1xUnF35naPGU63xwRDVGc-DkZ3M8V5mMk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S3Wj_mIZ8S3K"
      },
      "source": [
        "## Install `Tensorflow2.0` "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v9kv9tyJ77eF"
      },
      "source": [
        "## Get Required Files from Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D0O_n6OIEVyL",
        "outputId": "28973dae-0573-427c-e488-4bf4e7342782",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu7J7qt5UzJV",
        "colab_type": "code",
        "outputId": "7f00b9d0-9c02-4d28-e180-e9e74401cc26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "import warnings\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import preprocessing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pprint\n",
        "from tensorflow.keras.layers import Bidirectional,LSTM,Dense,Dropout,BatchNormalization,Flatten,Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from numpy import array\n",
        "import nltk\n",
        "import re\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize \n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8aLqG3XU42E",
        "colab_type": "code",
        "outputId": "44e7590e-d6e5-496d-dabf-2288125d071d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0mgRpOvFMjKR",
        "colab": {}
      },
      "source": [
        "#Set your project path \n",
        "project_path = \"/content/drive/My Drive/\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WXYwajPeQbRq"
      },
      "source": [
        "#**## Reading and Exploring Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vAk6BRUh8CqL"
      },
      "source": [
        "## Read Data \"Sarcasm_Headlines_Dataset.json\". Explore the data and get  some insights about the data. ( 4 marks)\n",
        "Hint - As its in json format you need to use pandas.read_json function. Give paraemeter lines = True."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwtEDqqUgE0S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path=\"/content/drive/My Drive/Sarcasm Detection/Data/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "StSLB-T8PuGr",
        "colab": {}
      },
      "source": [
        "df=pd.read_json(\"/content/drive/My Drive/Sarcasm Detection/Data/Sarcasm_Headlines_Dataset.json\",lines=True )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YksEdfTdWNpg",
        "colab_type": "code",
        "outputId": "abcbe8dd-fa55-4159-f367-b3707e26480f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_link</th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
              "      <td>former versace store clerk sues over secret 'b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
              "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
              "      <td>mom starting to fear son's web series closest ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
              "      <td>boehner just wants wife to listen, not come up...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
              "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        article_link  ... is_sarcastic\n",
              "0  https://www.huffingtonpost.com/entry/versace-b...  ...            0\n",
              "1  https://www.huffingtonpost.com/entry/roseanne-...  ...            0\n",
              "2  https://local.theonion.com/mom-starting-to-fea...  ...            1\n",
              "3  https://politics.theonion.com/boehner-just-wan...  ...            1\n",
              "4  https://www.huffingtonpost.com/entry/jk-rowlin...  ...            0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z6pXf7A78E2H"
      },
      "source": [
        "## Drop `article_link` from dataset. ( 2 marks)\n",
        "As we only need headline text data and is_sarcastic column for this project. We can drop artical link column here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VLSVsvrlP9qD",
        "colab": {}
      },
      "source": [
        "df1=df.drop(labels='article_link', axis=1,inplace=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72n8hgLFWkL_",
        "colab_type": "code",
        "outputId": "deae3cda-f844-44f4-d71b-f303c82ad16a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "df.head(2)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>former versace store clerk sues over secret 'b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            headline  is_sarcastic\n",
              "0  former versace store clerk sues over secret 'b...             0\n",
              "1  the 'roseanne' revival catches up to our thorn...             0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vPXhyUNYObF",
        "colab_type": "code",
        "outputId": "0fae636a-cebf-47f4-9cde-44e8aad88562",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26709, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-8P-zkAacDA",
        "colab_type": "code",
        "outputId": "7966d66f-7eb7-42b0-c103-10c00c484c6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "headline        object\n",
              "is_sarcastic     int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyagoOLbYRiI",
        "colab_type": "code",
        "outputId": "760924aa-2ee0-4528-dbe4-057843ee6ba7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "df['is_sarcastic'].value_counts()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    14985\n",
              "1    11724\n",
              "Name: is_sarcastic, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "D0h6IOxU8OdH"
      },
      "source": [
        "## Get the Length of each line and find the maximum length. ( 4 marks)\n",
        "As different lines are of different length. We need to pad the our sequences using the max length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BRAsChZAQmr3",
        "outputId": "bab0795e-7ff8-477d-f6cd-a8b10e4c2bf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "headline_max_length=max(len(txt) for txt in df['headline'])\n",
        "headline_max_length"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "254"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3ZidJh9b3jT",
        "colab_type": "code",
        "outputId": "f55f539a-f18d-4278-b0b4-e5f23417d3dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(df['headline']) #Fit it on Headlines\n",
        "input_seq = tokenizer.texts_to_sequences(df['headline'])\n",
        "input_seq[0:2] #Display some converted sentences"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[307, 15114, 678, 3336, 2297, 47, 381, 2575, 15115, 5, 2576, 8433],\n",
              " [3, 8434, 3337, 2745, 21, 1, 165, 8435, 415, 3111, 5, 257, 8, 1001]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNN36RtXdW5d",
        "colab_type": "code",
        "outputId": "9301c2ad-ea1e-4eb8-ee92-630c0d1533be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab_size = len(tokenizer.word_index)\n",
        "print(vocab_size)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29656\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2qPge7Pez5m",
        "colab_type": "code",
        "outputId": "87b881c1-d5c4-4ded-c49c-4790face9b91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "input_seq = tf.keras.preprocessing.sequence.pad_sequences(input_seq, \n",
        "                                                                   maxlen=headline_max_length,\n",
        "                                                                   padding='pre')\n",
        "print(input_seq.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(26709, 254)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VPPd0YuPXi2M"
      },
      "source": [
        "#**## Modelling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "35abKfRx8as3"
      },
      "source": [
        "## Import required modules required for modelling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DVel73hYEV4r",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Flatten, Bidirectional, GlobalMaxPool1D\n",
        "from tensorflow.keras.models import Model, Sequential"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9ziybaD1RdD9"
      },
      "source": [
        "# Set Different Parameters for the model. ( 2 marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jPw9gAN_EV6m",
        "colab": {}
      },
      "source": [
        "max_features = 10000\n",
        "maxlen = headline_max_length\n",
        "embedding_size = 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9abSe-bM8fn9"
      },
      "source": [
        "## Apply Keras Tokenizer of headline column of your data.  ( 4 marks)\n",
        "Hint - First create a tokenizer instance using Tokenizer(num_words=max_features) \n",
        "And then fit this tokenizer instance on your data column df['headline'] using .fit_on_texts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0Ffi63KsST3P"
      },
      "source": [
        "# Define X and y for your model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wnjxBdqmSS4s",
        "outputId": "5bfd7606-2c1d-4489-90b7-081d01640852",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "X = tokenizer.texts_to_sequences(df['headline'])\n",
        "X = pad_sequences(X, maxlen = maxlen)\n",
        "y = np.asarray(df['is_sarcastic'])\n",
        "\n",
        "print(\"Number of Samples:\", len(X))\n",
        "print(X[0])\n",
        "print(\"Number of Labels: \", len(y))\n",
        "print(y[0])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Samples: 26709\n",
            "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0   307 15114   678  3336  2297    47   381  2575 15115     5\n",
            "  2576  8433]\n",
            "Number of Labels:  26709\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCHmQQuhfibI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=input_seq\n",
        "y=np.asarray(df['is_sarcastic'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUo0SdmAoj1n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2, \n",
        "    random_state=42\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4BTBLgnmrlb",
        "colab_type": "code",
        "outputId": "31d0c0f4-828b-43b6-dc4e-9d3d8b9c3124",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_val.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5342,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YGt_kETsQEk",
        "colab_type": "code",
        "outputId": "a5e624c0-3575-4848-e510-ebe490fc1148",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21367, 254)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WJLyKg-98rH_"
      },
      "source": [
        "## Get the Vocabulary size ( 2 marks)\n",
        "Hint : You can use tokenizer.word_index."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q-2w0gHEUUIo",
        "outputId": "e5961232-fd80-40ae-ff08-2ac66b7a4c78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab_size = len(tokenizer.word_index)\n",
        "print(vocab_size)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29656\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5hjeMi40XcB1"
      },
      "source": [
        "#**## Word Embedding**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bUF1TuQa8ux0"
      },
      "source": [
        "## Get Glove Word Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vq5AIfRtMeZh",
        "colab": {}
      },
      "source": [
        "glove_file = data_path + \"glove.6B.zip\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DJLX_n2WMecA",
        "colab": {}
      },
      "source": [
        "#Extract Glove embedding zip file\n",
        "from zipfile import ZipFile\n",
        "with ZipFile(glove_file, 'r') as z:\n",
        "  z.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9IuXlu8-U3HG"
      },
      "source": [
        "# Get the Word Embeddings using Embedding file as given below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "elZ-T5aFGZmZ",
        "colab": {}
      },
      "source": [
        "EMBEDDING_FILE = './glove.6B.200d.txt'\n",
        "\n",
        "embeddings = {}\n",
        "for o in open(EMBEDDING_FILE):\n",
        "    word = o.split(\" \")[0]\n",
        "    # print(word)\n",
        "    embd = o.split(\" \")[1:]\n",
        "    embd = np.asarray(embd, dtype='float32')\n",
        "    # print(embd)\n",
        "    embeddings[word] = embd\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bTPxveDmVCrA"
      },
      "source": [
        "# Create a weight matrix for words in training docs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xQgOhiywU9nU",
        "outputId": "1734c170-5dc0-472d-d43b-e72052ee58ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embedding_matrix = np.zeros((vocab_size+1, 200))\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "len(embeddings.values())"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "u7IbWuEX82Ra"
      },
      "source": [
        "## Create and Compile your Model  ( 7 marks)\n",
        "Hint - Use Sequential model instance and then add Embedding layer, Bidirectional(LSTM) layer, then dense and dropout layers as required. \n",
        "In the end add a final dense layer with sigmoid activation for binary classification.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d7jhsSgYXG4l",
        "colab": {}
      },
      "source": [
        "### Embedding layer for hint \n",
        "## model.add(Embedding(num_words, embedding_size, weights = [embedding_matrix]))\n",
        "### Bidirectional LSTM layer for hint \n",
        "## model.add(Bidirectional(LSTM(128, return_sequences = True)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rQIPWJHpUBe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJVwjeN0pV1j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.Embedding(input_dim=vocab_size+1,\n",
        "                  output_dim=embedding_size,\n",
        "                  weights=[embedding_matrix],\n",
        "                  trainable=False, mask_zero= True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MUIk7vdg5yT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Bidirectional(LSTM(units=128,return_sequences=False),merge_mode='concat'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCdJaacGqEqL",
        "colab_type": "code",
        "outputId": "9322cea0-660f-493f-97d2-dadad3dd9d04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.output"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'bidirectional/Identity:0' shape=(None, 256) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-eEunanqJGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.Dense(1,activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xq1yHwWhqP2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhkQADcbqoCq",
        "colab_type": "code",
        "outputId": "03e44d7a-7044-4bd1-e732-2955a3ef5570",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 200)         5931400   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, None, 200)         0         \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 256)               336896    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 6,268,553\n",
            "Trainable params: 337,153\n",
            "Non-trainable params: 5,931,400\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IJFMxZwMWoTw"
      },
      "source": [
        "# Fit your model with a batch size of 100 and validation_split = 0.2. and state the validation accuracy ( 5 marks)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZpVkajCcWnRK",
        "colab": {}
      },
      "source": [
        "batch_size = 100\n",
        "epochs = 5\n",
        "\n",
        "## Add your code here ##"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0ErE3BLmKaH",
        "colab_type": "code",
        "outputId": "e88c8bd4-5762-4473-c4fe-04b728f46f78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "model.fit(X_train,y_train,\n",
        "          epochs=5,\n",
        "          batch_size=100, validation_data=(X_val, y_val))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "214/214 [==============================] - 324s 2s/step - loss: 0.4921 - accuracy: 0.7584 - val_loss: 0.3962 - val_accuracy: 0.8192\n",
            "Epoch 2/5\n",
            "214/214 [==============================] - 322s 2s/step - loss: 0.3610 - accuracy: 0.8369 - val_loss: 0.3418 - val_accuracy: 0.8484\n",
            "Epoch 3/5\n",
            "214/214 [==============================] - 321s 2s/step - loss: 0.2995 - accuracy: 0.8703 - val_loss: 0.3026 - val_accuracy: 0.8718\n",
            "Epoch 4/5\n",
            "214/214 [==============================] - 318s 1s/step - loss: 0.2561 - accuracy: 0.8930 - val_loss: 0.3023 - val_accuracy: 0.8706\n",
            "Epoch 5/5\n",
            "214/214 [==============================] - 316s 1s/step - loss: 0.2184 - accuracy: 0.9114 - val_loss: 0.2944 - val_accuracy: 0.8774\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2a001aaf60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s30jaAS1Oxob",
        "colab_type": "text"
      },
      "source": [
        "Validation Accuracy with Embedding size of 200 and RNN Units of 128 is 87.74"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffEM9RlzOnBM",
        "colab_type": "text"
      },
      "source": [
        "# Model 2- Glove Embedding of 300, With 256 Memory Size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tF3vRSCOlIH",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6_MJYLOqflo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMBEDDING_FILE = './glove.6B.300d.txt'\n",
        "\n",
        "embeddings = {}\n",
        "for o in open(EMBEDDING_FILE):\n",
        "    word = o.split(\" \")[0]\n",
        "    # print(word)\n",
        "    embd = o.split(\" \")[1:]\n",
        "    embd = np.asarray(embd, dtype='float32')\n",
        "    # print(embd)\n",
        "    embeddings[word] = embd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DBndY2XNrXW",
        "colab_type": "code",
        "outputId": "f9ed0b61-acb7-482e-f787-30eab501ed3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embedding_matrix = np.zeros((vocab_size+1, 300))\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "len(embeddings.values())"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyZwZJgVNw7Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2 = tf.keras.Sequential()\n",
        "model2.add(tf.keras.layers.Embedding(input_dim=vocab_size+1,\n",
        "                  output_dim=300,\n",
        "                  weights=[embedding_matrix],\n",
        "                  trainable=False, mask_zero= True))\n",
        "model2.add(tf.keras.layers.Dropout(0.2))\n",
        "model2.add(tf.keras.layers.Bidirectional(LSTM(units=256,return_sequences=False),merge_mode='concat'))\n",
        "model2.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
        "model2.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRm5h0Az2ieX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPE8IAH1OPTE",
        "colab_type": "code",
        "outputId": "141dce33-2b14-4d8a-92b8-be0e1b50623c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "model2.fit(X_train,y_train,\n",
        "          epochs=5,\n",
        "          batch_size=100, validation_data=(X_val, y_val))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "214/214 [==============================] - 220s 1s/step - loss: 0.4546 - accuracy: 0.7835 - val_loss: 0.3662 - val_accuracy: 0.8371\n",
            "Epoch 2/5\n",
            "214/214 [==============================] - 220s 1s/step - loss: 0.3299 - accuracy: 0.8539 - val_loss: 0.3260 - val_accuracy: 0.8551\n",
            "Epoch 3/5\n",
            "214/214 [==============================] - 220s 1s/step - loss: 0.2610 - accuracy: 0.8905 - val_loss: 0.3036 - val_accuracy: 0.8678\n",
            "Epoch 4/5\n",
            "214/214 [==============================] - 218s 1s/step - loss: 0.2098 - accuracy: 0.9156 - val_loss: 0.2934 - val_accuracy: 0.8761\n",
            "Epoch 5/5\n",
            "214/214 [==============================] - 217s 1s/step - loss: 0.1552 - accuracy: 0.9389 - val_loss: 0.3134 - val_accuracy: 0.8757\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f970793a0b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbkXFpjcg_d_",
        "colab_type": "text"
      },
      "source": [
        "Validation Accuracy with Embedding size of 300 and RNN Units of 256 is 87.57"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dN_2jmSb5QpO",
        "colab_type": "text"
      },
      "source": [
        "# Model 3- Glove Embedding of 300, With 128 Memory Size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ofFzHPq5YTk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model3 = tf.keras.Sequential()\n",
        "model3.add(tf.keras.layers.Embedding(input_dim=vocab_size+1,\n",
        "                  output_dim=300,\n",
        "                  weights=[embedding_matrix],\n",
        "                  trainable=False, mask_zero= True))\n",
        "model3.add(tf.keras.layers.Dropout(0.2))\n",
        "model3.add(tf.keras.layers.Bidirectional(LSTM(units=128,return_sequences=False),merge_mode='concat'))\n",
        "model3.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
        "model3.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHIaVeGR5ury",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "661684ed-4458-492e-dc9a-ee0f6ff1c940"
      },
      "source": [
        "model3.summary()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, None, 300)         8897100   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, None, 300)         0         \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 256)               439296    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 9,336,653\n",
            "Trainable params: 439,553\n",
            "Non-trainable params: 8,897,100\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHGmbgNV6C7h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "91e25376-4aaf-4966-9473-9d32b67ad211"
      },
      "source": [
        "model3.fit(X_train,y_train,\n",
        "          epochs=15,\n",
        "          batch_size=100, validation_data=(X_val, y_val))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "214/214 [==============================] - 216s 1s/step - loss: 0.1345 - accuracy: 0.9509 - val_loss: 0.3294 - val_accuracy: 0.8720\n",
            "Epoch 2/15\n",
            "214/214 [==============================] - 214s 1000ms/step - loss: 0.1037 - accuracy: 0.9620 - val_loss: 0.3336 - val_accuracy: 0.8808\n",
            "Epoch 3/15\n",
            "214/214 [==============================] - 214s 1s/step - loss: 0.0829 - accuracy: 0.9701 - val_loss: 0.3479 - val_accuracy: 0.8819\n",
            "Epoch 4/15\n",
            "214/214 [==============================] - 213s 994ms/step - loss: 0.0632 - accuracy: 0.9786 - val_loss: 0.3914 - val_accuracy: 0.8778\n",
            "Epoch 5/15\n",
            "214/214 [==============================] - 213s 993ms/step - loss: 0.0489 - accuracy: 0.9834 - val_loss: 0.3836 - val_accuracy: 0.8815\n",
            "Epoch 6/15\n",
            "214/214 [==============================] - 214s 1s/step - loss: 0.0355 - accuracy: 0.9887 - val_loss: 0.4166 - val_accuracy: 0.8871\n",
            "Epoch 7/15\n",
            "214/214 [==============================] - 214s 999ms/step - loss: 0.0323 - accuracy: 0.9897 - val_loss: 0.4527 - val_accuracy: 0.8765\n",
            "Epoch 8/15\n",
            "214/214 [==============================] - 213s 997ms/step - loss: 0.0261 - accuracy: 0.9914 - val_loss: 0.4466 - val_accuracy: 0.8783\n",
            "Epoch 9/15\n",
            "214/214 [==============================] - 214s 1000ms/step - loss: 0.0262 - accuracy: 0.9916 - val_loss: 0.4795 - val_accuracy: 0.8789\n",
            "Epoch 10/15\n",
            "214/214 [==============================] - 212s 992ms/step - loss: 0.0259 - accuracy: 0.9910 - val_loss: 0.5278 - val_accuracy: 0.8654\n",
            "Epoch 11/15\n",
            "214/214 [==============================] - 214s 1s/step - loss: 0.0177 - accuracy: 0.9946 - val_loss: 0.4938 - val_accuracy: 0.8774\n",
            "Epoch 12/15\n",
            "214/214 [==============================] - 214s 999ms/step - loss: 0.0163 - accuracy: 0.9956 - val_loss: 0.5086 - val_accuracy: 0.8772\n",
            "Epoch 13/15\n",
            "214/214 [==============================] - 214s 998ms/step - loss: 0.0152 - accuracy: 0.9958 - val_loss: 0.5239 - val_accuracy: 0.8766\n",
            "Epoch 14/15\n",
            "214/214 [==============================] - 214s 1000ms/step - loss: 0.0144 - accuracy: 0.9958 - val_loss: 0.5307 - val_accuracy: 0.8830\n",
            "Epoch 15/15\n",
            "214/214 [==============================] - 214s 1000ms/step - loss: 0.0150 - accuracy: 0.9954 - val_loss: 0.5313 - val_accuracy: 0.8746\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f96b45bb208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VRsPwcX-ZcI",
        "colab_type": "text"
      },
      "source": [
        "Validation Accuracy with Embedding size of 300 and RNN Units of 128 is 87.46"
      ]
    }
  ]
}